{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Libraries\n",
        "\n",
        "###**Demonstrating the process of loading a pre-trained GPT-2 model and tokenizer using the Hugging Face's Transformers library.**\n",
        "\n",
        "1. Import the necessary libraries:\n",
        "   - `tensorflow` library for TensorFlow functionalities\n",
        "   - `GPT2Tokenizer` and `TFGPT2LMHeadModel` from the `transformers` module for GPT-2 model and tokenizer\n",
        "\n",
        "2. Import the `pad_sequences` function from tensorflow for padding sequences.\n",
        "\n",
        "3. Load the pre-trained GPT-2 model and tokenizer:\n",
        "   - `model_name` variable stores the name of the pre-trained GPT-2 model to be loaded (in this case, it is \"gpt2\").\n",
        "   - `tokenizer` is initialized using `GPT2Tokenizer.from_pretrained(model_name)`, which loads the tokenizer for the specified model.\n",
        "   - `model` is initialized using `TFGPT2LMHeadModel.from_pretrained(model_name)`, which loads the pre-trained GPT-2 model.\n"
      ],
      "metadata": {
        "id": "3bxfT-44gvGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load pre-trained GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = TFGPT2LMHeadModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO7-ExV9GQ8p",
        "outputId": "257f0ea2-a60d-4746-884e-9fdc424dfbc1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data for Fine-tuning the model"
      ],
      "metadata": {
        "id": "qgLa8-Dug_7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "medical_queries = [\"What are the symptoms of COVID-19?\",\n",
        "                   \"How can I prevent the flu?\",\n",
        "                   \"What are the treatment options for diabetes?\",\n",
        "                   \"What causes migraines?\",\n",
        "                   \"Is there a cure for asthma?\",\n",
        "                   \"What are the signs of a heart attack?\",\n",
        "                   \"How can I manage my anxiety?\",\n",
        "                   \"What are the risk factors for high blood pressure?\",\n",
        "                   \"What is the recommended diet for someone with celiac disease?\",\n",
        "                   \"What are the symptoms of depression?\"]\n",
        "\n",
        "responses = [\"Common symptoms of COVID-19 include fever, cough, and difficulty breathing.\",\n",
        "             \"To prevent the flu, you can get vaccinated annually and practice good hand hygiene.\",\n",
        "             \"Treatment options for diabetes may include lifestyle changes, medication, and insulin therapy.\",\n",
        "             \"Migraines can be caused by various factors such as hormonal changes, certain foods, and stress.\",\n",
        "             \"While there is no cure for asthma, it can be managed with medications and lifestyle changes.\",\n",
        "             \"Signs of a heart attack include chest pain, shortness of breath, and pain radiating to the left arm.\",\n",
        "             \"Managing anxiety may involve therapy, medication, and adopting relaxation techniques.\",\n",
        "             \"Risk factors for high blood pressure include obesity, sedentary lifestyle, and a family history of hypertension.\",\n",
        "             \"A recommended diet for someone with celiac disease involves avoiding gluten-containing foods like wheat, barley, and rye.\",\n",
        "             \"Symptoms of depression can include persistent sadness, loss of interest, and changes in sleep and appetite.\"]"
      ],
      "metadata": {
        "id": "mrQsIs2hfrRH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Demonstrating the process of tokenizing and encoding input queries & responses using tokenizer.**\n",
        "\n",
        "1. Initialize empty lists to store the tokenized input queries and responses:\n",
        "   - `input_ids` list will store the tokenized input queries.\n",
        "   - `labels` list will store the tokenized input responses.\n",
        "\n",
        "2. Iterate over the `medical_queries` and `responses` using the `zip` function to process each pair of query and response.\n",
        "\n",
        "3. Check if the query or response is None:\n",
        "   - If either the query or response is None, skip to the next iteration using the `continue` statement.\n",
        "\n",
        "4. Tokenize and encode the query and response:\n",
        "   - `encoded_input` variable stores the tokenized and encoded representation of the query using the tokenizer's `encode` method. The `add_special_tokens=True` argument adds special tokens to the sequence.\n",
        "   - `encoded_response` variable stores the tokenized and encoded representation of the response using the same approach.\n",
        "\n",
        "5. Append the encoded query and response to the respective lists:\n",
        "   - `input_ids` list appends the `encoded_input`.\n",
        "   - `labels` list appends the `encoded_response`.\n",
        "\n",
        "6. Pad the input_ids and labels sequences:\n",
        "   - Determine the `max_seq_length` as the maximum length among all sequences in `input_ids` and `labels`.\n",
        "   - Use the `pad_sequences` function to pad the `input_ids` sequences with zeros at the end (`padding='post'`) up to `max_seq_length` length (`maxlen=max_seq_length`) and store the result back in `input_ids`.\n",
        "   - Use the same approach to pad the `labels` sequences, but with `max_seq_length - 1` as `maxlen` to exclude the last token.\n",
        "\n",
        "## Usage ⬇️\n",
        "\n",
        "The provided code snippet can be used to tokenize and encode input queries and responses using a tokenizer. It prepares the data for training a model that requires encoded sequences.\n"
      ],
      "metadata": {
        "id": "JqlF6g3uhQrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "labels = []\n",
        "for query, response in zip(medical_queries, responses):\n",
        "    if query is None or response is None:\n",
        "        continue\n",
        "    encoded_input = tokenizer.encode(query, add_special_tokens=True)\n",
        "    encoded_response = tokenizer.encode(response, add_special_tokens=True)\n",
        "    input_ids.append(encoded_input)\n",
        "    labels.append(encoded_response)\n",
        "\n",
        "# Pad the input_ids and labels sequences\n",
        "max_seq_length = max(len(seq) for seq in input_ids + labels)\n",
        "input_ids = pad_sequences(input_ids, padding='post', maxlen=max_seq_length, dtype='int32')\n",
        "labels = pad_sequences(labels, padding='post', maxlen=max_seq_length - 1, dtype='int32')"
      ],
      "metadata": {
        "id": "IJS2ArWdgD6J"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the input sequences to TensorFlow dataset\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((input_ids, labels))\n",
        "\n",
        "# Convert the TensorFlow dataset to an iterable\n",
        "train_iter = iter(train_dataset)\n",
        "\n",
        "# Print the contents of the train_dataset\n",
        "for i, (inputs, labels) in enumerate(train_iter):\n",
        "    print(f\"Example {i + 1}:\")\n",
        "    print(\"Input IDs:\", inputs)\n",
        "    print(\"Labels:\", labels)\n",
        "    print()"
      ],
      "metadata": {
        "id": "6IAfEqipfwO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Fine-tuning the model using the defined training parameters.**\n",
        "\n",
        "1. Define the training parameters:\n",
        "   - `batch_size` represents the number of training examples in each batch.\n",
        "   - `num_epochs` specifies the total number of training epochs.\n",
        "   - `optimizer` is an instance of the Adam optimizer, responsible for updating the model's weights during training.\n",
        "   - `loss_fn` defines the loss function used to calculate the model's training loss.\n",
        "\n",
        "2. Define the training loop:\n",
        "   - `num_batches` calculates the number of batches based on the length of the training dataset and the batch size.\n",
        "   - The outer loop iterates over the specified number of epochs.\n",
        "   - The inner loop iterates over the batches of the training dataset, obtained using the `batch` method.\n",
        "   - Within each batch, the model's forward pass is executed using the current inputs.\n",
        "   - The loss value is calculated by comparing the predicted logits with the corresponding labels, excluding the last token.\n",
        "   - The gradients of the model's trainable variables with respect to the loss are computed using a gradient tape.\n",
        "   - The optimizer applies the gradients to update the model's weights.\n",
        "   - The training progress is periodically printed, showing the current epoch, batch, and loss value.\n",
        "\n",
        "3. Save the fine-tuned model:\n",
        "   - After the training loop completes, the fine-tuned model is saved using the `save_pretrained` method, specifying the desired save directory.\n",
        "\n",
        "## Usage ⬇️\n",
        "\n",
        "The provided code snippet serves as a reference for fine-tuning a model using TensorFlow and the specified training parameters. Modify the parameters and adapt the code according to task and dataset.\n"
      ],
      "metadata": {
        "id": "-6hMkJ2PjUEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the training parameters\n",
        "batch_size = 4\n",
        "num_epochs = 3\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "\n",
        "# Define the model and loss function\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Define the training loop\n",
        "num_batches = len(train_dataset) // batch_size\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    for step, (inputs, labels) in enumerate(train_dataset.batch(batch_size)):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(inputs)[0]\n",
        "            loss_value = loss_fn(labels, logits[:, :-1, :])  # Exclude the last token from logits\n",
        "\n",
        "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "        if step % 10 == 0:\n",
        "            print(f\"  Batch {step}/{num_batches} - Loss: {loss_value:.4f}\")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"./fine_tuned_model\")"
      ],
      "metadata": {
        "id": "yu2dR4zYfz0f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}